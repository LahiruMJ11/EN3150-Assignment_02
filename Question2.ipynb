{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5846680f",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "' penguins ' is not one of the example datasets.",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 8\u001b[39m\n\u001b[32m      6\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msklearn\u001b[39;00m . metrics \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01maccuracy_score\u001b[39;00m\n\u001b[32m      7\u001b[39m \u001b[38;5;66;03m# Load the penguins dataset\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m8\u001b[39m df = \u001b[43msns\u001b[49m\u001b[43m \u001b[49m\u001b[43m.\u001b[49m\u001b[43m \u001b[49m\u001b[43mload_dataset\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m penguins \u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m      9\u001b[39m df. dropna ( inplace = \u001b[38;5;28;01mTrue\u001b[39;00m )\n\u001b[32m     10\u001b[39m \u001b[38;5;66;03m# Filter rows for 'Adelie ' and 'Chinstrap ' classes\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\Python\\Python313\\site-packages\\seaborn\\utils.py:573\u001b[39m, in \u001b[36mload_dataset\u001b[39m\u001b[34m(name, cache, data_home, **kws)\u001b[39m\n\u001b[32m    571\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m os.path.exists(cache_path):\n\u001b[32m    572\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m get_dataset_names():\n\u001b[32m--> \u001b[39m\u001b[32m573\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m\u001b[33m is not one of the example datasets.\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    574\u001b[39m     urlretrieve(url, cache_path)\n\u001b[32m    575\u001b[39m full_path = cache_path\n",
      "\u001b[31mValueError\u001b[39m: ' penguins ' is not one of the example datasets."
     ]
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "from sklearn . model_selection import train_test_split\n",
    "from sklearn . preprocessing import LabelEncoder\n",
    "from sklearn . linear_model import LogisticRegression\n",
    "from sklearn . metrics import accuracy_score\n",
    "# Load the penguins dataset\n",
    "df = sns . load_dataset (\" penguins \")\n",
    "df. dropna ( inplace = True )\n",
    "# Filter rows for 'Adelie ' and 'Chinstrap ' classes\n",
    "selected_classes = ['Adelie ', 'Chinstrap ']\n",
    "df_filtered = df[df['species ']. isin ( selected_classes )]. copy ()\n",
    "# Make a copy to avoid the warning\n",
    "# Initialize the LabelEncoder\n",
    "le = LabelEncoder ()\n",
    "# Encode the species column\n",
    "y_encoded = le. fit_transform ( df_filtered ['species '])\n",
    "df_filtered [' class_encoded '] = y_encoded\n",
    "# Display the filtered and encoded DataFrame\n",
    "print ( df_filtered [[ 'species ', ' class_encoded ']])\n",
    "# Split the data into features (X) and target variable (y)\n",
    "y = df_filtered [' class_encoded '] # Target variable\n",
    "X = df_filtered . drop ([ ' class_encoded '], axis =1)\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train , X_test , y_train , y_test = train_test_split (X, y,\n",
    "test_size =0.2 , random_state =42)\n",
    "# Train the logistic regression model . Here we are using saga\n",
    "# solver to learn weights .\n",
    "logreg = LogisticRegression ( solver ='saga ')\n",
    "logreg . fit ( X_train , y_train )\n",
    "# Predict on the testing data\n",
    "y_pred = logreg . predict ( X_test )\n",
    "# Evaluate the model\n",
    "accuracy = accuracy_score ( y_test , y_pred )\n",
    "print (\" Accuracy :\", accuracy )\n",
    "print ( logreg .coef_ , logreg . intercept_ )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e9ebb42a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  species  class_encoded\n",
      "0  Adelie              0\n",
      "1  Adelie              0\n",
      "2  Adelie              0\n",
      "4  Adelie              0\n",
      "5  Adelie              0\n",
      "Accuracy: 0.6744186046511628\n",
      "Coefficients shape: (1, 7)\n",
      "Intercept: [-8.8967178e-05]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\DELL\\AppData\\Roaming\\Python\\Python313\\site-packages\\sklearn\\linear_model\\_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Load the penguins dataset\n",
    "df = sns.load_dataset(\"penguins\")\n",
    "df.dropna(inplace=True)\n",
    "\n",
    "# Filter rows for 'Adelie' and 'Chinstrap' classes (exact names, no extra spaces)\n",
    "selected_classes = ['Adelie', 'Chinstrap']\n",
    "df_filtered = df[df['species'].isin(selected_classes)].copy()\n",
    "\n",
    "# Initialize the LabelEncoder for the target\n",
    "le = LabelEncoder()\n",
    "\n",
    "# Encode the species column as the target (0/1)\n",
    "y_encoded = le.fit_transform(df_filtered['species'])\n",
    "df_filtered['class_encoded'] = y_encoded\n",
    "\n",
    "# Display the filtered and encoded DataFrame (optional)\n",
    "print(df_filtered[['species', 'class_encoded']].head())\n",
    "\n",
    "# Build feature matrix X:\n",
    "#   1) Drop the target columns ('class_encoded' and the original 'species')\n",
    "#   2) One-hot encode remaining categorical features to ensure X is numeric\n",
    "X = df_filtered.drop(['class_encoded', 'species'], axis=1)\n",
    "X = pd.get_dummies(X, drop_first=True)\n",
    "\n",
    "# Target\n",
    "y = df_filtered['class_encoded']\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "# Train the logistic regression model with saga solver\n",
    "logreg = LogisticRegression(solver='saga', max_iter=1000, random_state=42)\n",
    "logreg.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the testing data\n",
    "y_pred = logreg.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"Coefficients shape:\", logreg.coef_.shape)\n",
    "print(\"Intercept:\", logreg.intercept_)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e80e605",
   "metadata": {},
   "source": [
    "With liblinear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7fc9a3af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9767441860465116\n",
      "Coefficients shape: (1, 7)\n",
      "Intercept: [-0.03449285]\n"
     ]
    }
   ],
   "source": [
    "# Train the logistic regression model with liblinear solver\n",
    "logreg = LogisticRegression(solver='liblinear', max_iter=1000, random_state=42)\n",
    "logreg.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the testing data\n",
    "y_pred = logreg.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"Coefficients shape:\", logreg.coef_.shape)\n",
    "print(\"Intercept:\", logreg.intercept_)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eebb152f",
   "metadata": {},
   "source": [
    "With Standard Scalar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad156332",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy comparison (same split):\n",
      "  liblinear_no_scale: 0.9767\n",
      "    liblinear_scaled: 1.0000\n",
      "       saga_no_scale: 0.6744\n",
      "         saga_scaled: 1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\DELL\\AppData\\Roaming\\Python\\Python313\\site-packages\\sklearn\\linear_model\\_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Compare liblinear vs saga with and without StandardScaler (numeric-only scaling)\n",
    "\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# 1) Load data and filter to binary classes\n",
    "df = sns.load_dataset(\"penguins\").dropna().copy()\n",
    "df = df[df[\"species\"].isin([\"Adelie\", \"Chinstrap\"])].copy()\n",
    "\n",
    "# Target\n",
    "y = (df[\"species\"] == \"Chinstrap\").astype(int)  # Adelie -> 0, Chinstrap -> 1\n",
    "\n",
    "# Feature set: numeric + categorical\n",
    "num_cols = [\"bill_length_mm\", \"bill_depth_mm\", \"flipper_length_mm\", \"body_mass_g\"]\n",
    "cat_cols = [\"island\", \"sex\"]\n",
    "X = df[num_cols + cat_cols].reset_index(drop=True)\n",
    "\n",
    "# Train/test split (stratify for class balance)\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "# 2) Preprocessing variants\n",
    "preprocess_no_scale = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"num\", \"passthrough\", num_cols),\n",
    "        (\"cat\", OneHotEncoder(handle_unknown=\"ignore\"), cat_cols),\n",
    "    ],\n",
    "    remainder=\"drop\",\n",
    ")\n",
    "\n",
    "preprocess_scaled = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"num\", StandardScaler(), num_cols),\n",
    "        (\"cat\", OneHotEncoder(handle_unknown=\"ignore\"), cat_cols),\n",
    "    ],\n",
    "    remainder=\"drop\",\n",
    ")\n",
    "\n",
    "# 3) Models\n",
    "liblinear = LogisticRegression(solver=\"liblinear\", max_iter=1000, random_state=42)\n",
    "saga = LogisticRegression(solver=\"saga\", penalty=\"l2\", max_iter=1000, random_state=42)\n",
    "\n",
    "# 4) Pipelines\n",
    "pipelines = {\n",
    "    \"liblinear_no_scale\": Pipeline([(\"prep\", preprocess_no_scale), (\"clf\", liblinear)]),\n",
    "    \"liblinear_scaled\":   Pipeline([(\"prep\", preprocess_scaled),   (\"clf\", liblinear)]),\n",
    "    \"saga_no_scale\":      Pipeline([(\"prep\", preprocess_no_scale), (\"clf\", saga)]),\n",
    "    \"saga_scaled\":        Pipeline([(\"prep\", preprocess_scaled),   (\"clf\", saga)]),\n",
    "}\n",
    "\n",
    "# 5) Fit, predict, evaluate\n",
    "results = {}\n",
    "for name, pipe in pipelines.items():\n",
    "    pipe.fit(X_train, y_train)\n",
    "    y_pred = pipe.predict(X_test)\n",
    "    acc = accuracy_score(y_test, y_pred)\n",
    "    results[name] = acc\n",
    "\n",
    "# 6) Print results\n",
    "print(\"Accuracy comparison (same split):\")\n",
    "for k, v in results.items():\n",
    "    print(f\"{k:>20s}: {v:.4f}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
